@Book{lamport,
  author =	 {L[eslie] Lamport},
  title = 	 {{\LaTeX: A} Document Preparation System},
  publisher = 	 {Addison-Wesley},
  year = 	 1994
}

@Book{kopka,
  author =	 {H[elmut] Kopka and P[atrick] W[] Daly},
  title = 	 {Guide to {\LaTeX}},
  publisher = 	 {Addison-Wesley},
  year = 	 2004
}

@preamble{"\newcommand{\SortNoop}[1]{}"}
@Book{Cerveny,
  author = {V[] {\SortNoop{Cerveny}}\v{C}erven\'{y}},
  title = {Seismic Ray Method},
  year = {2000},
  publisher = {Cambridge University Press}
}

@PHDTHESIS{forgues96,
  author = {E. Forgues},
  title  = {Inversion linearis\'ee multi-param\`etres via la th\'eorie des rais},
  school = {Institut Fran\c{c}ais du P\'etrole - University Paris VII},
  year   = {1996}
}


@article{Datta2016,
	abstract = {Full-waveform inversion (FWI) has become a popular method to estimate elastic earth properties from seismograms. It is formulated as a data-fitting least-squares minimization problem that iteratively updates an initial velocity model with the scaled gradient of the misfit until a satisfactory match between the real and synthetic data is obtained. However, such a local optimization approach can converge to a local minimum if the starting model used is not close enough to an optimal model.We have developed a two-step process in which we first estimate a starting model using a global optimization method. Unlike local optimization methods, a global optimization method starts with a random starting model and is not generally susceptible to be trapped in a local minimum. The starting model for FWI that we aim to estimate is sparsely parameterized and contains a set of interfaces and velocities that are used to represent the entire velocity model. We have obtained the depth of the interfaces and the velocities by minimizing the data misfit in the least-squares sense using a global optimization method called very fast simulated annealing (VFSA). Once the sparse velocity model was obtained from VFSA, we used that as a starting model in a conventional gradient- based FWI to obtain the final model. We have applied the proposed method to one synthetic data set and two field data sets from offshore India. The proposed method was able to estimate a velocity model that was not cycle skipped for realistic frequency bands. We have demonstrated that with the proper choice of model parameterization and optimization parameters, the global and gradient optimization algorithms converge in a finite number of iterations. We have determined that the resulting algorithm is computationally feasible in two dimensions and accurate for practical implementation of FWI.},
	author = {Datta, Debanjan and Sen, Mrinal K.},
	doi = {10.1190/GEO2015-0339.1},
	file = {:C\:/Users/VIKAS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Datta, Sen - 2016 - Estimating a starting model for full-waveform inversion using a global optimization method(3).pdf:pdf},
	issn = {19422156},
	journal = {Geophysics},
	mendeley-groups = {global_optimization},
	number = {4},
	pages = {R211--R223},
	title = {{Estimating a starting model for full-waveform inversion using a global optimization method}},
	volume = {81},
	year = {2016}
}


@article{Fu2021,
	author = {Fu, Xin and Innanen, Kristopher A and Project, Crewes},
	file = {:C\:/Users/VIKAS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fu, Innanen, Project - 2021 - A new parallel simulated annealing algorithm for 1 . 5D acoustic full-waveform inversion.pdf:pdf},
	mendeley-groups = {global_optimization},
	pages = {1--3},
	title = {{A new parallel simulated annealing algorithm for 1 . 5D acoustic full-waveform inversion}},
	year = {2021}
}


@article{Shiba2005,
	abstract = {A source inversion method using very fast simulated annealing is proposed to estimate the earthquake rupture process, and associated radiation of broadband strong ground motions. We invert the displacement and velocity motions separately to estimate the spatio-temporal distributions of effective stress and moment. The developed method is applied to the near-source strong motions in the frequency range up to 5 Hz from the 1997 Izu-Hanto Toho-Oki earthquake (MJMA 5.9). Results of the displacement inversion indicate that for this earthquake the seismic moment is mainly released from the shallower region and the northern area from the hypocenter. Similar results are obtained from the velocity inversion, and the variation of the effective stress also exhibits a similar behavior to the moment distribution. Based on the inversion results, we propose a characterized source model that consists of the finite number of asperities and a background area with uniform effective stresses. The broadband ground motion simulation demonstrates that the characterized source model successfully reproduces the observed ground motions in spite of the simplification of actual (inverted) source process. This suggests our proposed inversion method and source characterization process are suitable for the strong-motion prediction that reflects the high-frequency radiation from an actual earthquake. {\textcopyright} 2005, The Seismological Society of Japan, Society of Geomagnetism and Earth, Planetary and Space Sciences, The Volcanological Society of Japan, The Geodetic Society of Japan, The Japanese Society for Planetary Sciences. All rights reserved.},
	author = {Shiba, Yoshiaki and Irikura, Kojiro},
	doi = {10.1186/BF03351837},
	file = {:C\:/Users/VIKAS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shiba, Irikura - 2005 - Rupture process by waveform inversion using simulated annealing and simulation of broadband ground motions.pdf:pdf},
	issn = {18805981},
	journal = {Earth, Planets and Space},
	keywords = {Waveform inversion,characterized source model,effective stress,empirical Green's function,simulated annealing},
	mendeley-groups = {global_optimization},
	number = {7},
	pages = {571--590},
	title = {{Rupture process by waveform inversion using simulated annealing and simulation of broadband ground motions}},
	volume = {57},
	year = {2005}
}

@article{Mendes2024,
	abstract = {the large number of simulations needed to adjust the simulation parameters. Although the first issue is a common concern of Full-waveform inversion (FWI) is a prominent method com-previous work, the second issue is usually neglected, relying monly used to create detailed velocity models of the subsurface. on trial and error. We introduce an approach to tackle the issues However, because it relies on gradient methods, it suffers from and then apply it within a simulated annealing framework we the limitation of getting trapped in local minima. To avoid this create. Our experiments using the Marmousi data yielded prom-problem, FWI needs to start from an initial velocity model that ising results when compared with previous work. We find that lies in the same region of convexity as the global minimum. our approach almost eliminated the computational effort to fine-Global optimization methods, such as simulated annealing, tune several simulation parameters. In addition, the number of can be used to find such an initial velocity model. However, iterations needed to explore the variables space is reduced by the iterative process of simulated annealing entails high computwo orders of magnitude. FWI is able to find a detailed velocity tational cost, first because of the large number of iterations model with high quality when using the initial velocity model needed to explore the variables space, and second because of generated by the method.},
	author = {Mendes, Rafael and Kaelin, Bruno and Mart{\'{i}}nez-Sansigre, Alejo and Barbosa and Bentes, Cristiana and Amorim},
	doi = {10.1190/GEO2023-0140.1},
	file = {:C\:/Users/VIKAS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mendes et al. - 2024 - Faster determination of an initial velocity model for full-waveform inversion based on simulated annealing.pdf:pdf},
	issn = {19422156},
	journal = {Geophysics},
	mendeley-groups = {global_optimization},
	number = {3},
	pages = {R187--R198},
	title = {{Faster determination of an initial velocity model for full-waveform inversion based on simulated annealing}},
	volume = {89},
	year = {2024}
}

@article{Datta2019,
	abstract = {A good starting model is imperative in full-waveform inversion (FWI) because it solves a least-squares inversion problem using a local gradient-based optimization method. A suboptimal starting model can result in cycle skipping leading to poor convergence and incorrect estimation of subsurface properties. This problem is especially crucial for salt models because the strong velocity contrasts create substantial time shifts in the modeled seismogram. Incorrect estimation of salt bodies leads to velocity inaccuracies in the sediments because the least-squares gradient aims to reduce traveltime differences without considering the sharp velocity jump between sediments and salt. We have developed a technique to estimate velocity models containing salt bodies using a combination of global and local optimization techniques. To stabilize the global optimization algorithm and keep it computationally tractable, we reduce the number of model parameters by using sparse parameterization formulations. The sparse formulation represents sediments using a set of interfaces and velocities across them, whereas a set of ellipses represents the salt body. We use very fast simulated annealing (VFSA) to minimize the misfit between the observed and synthetic data and estimate an optimal model in the sparsely parameterized space. The VFSA inverted model is then used as a starting model in FWI in which the sediments and salt body are updated in the least-squares sense. We partition model updates into sediment and salt updates in which the sediments are updated like conventional FWI, whereas the shape of the salt is updated by taking the zero crossing of an evolving level set surface. Our algorithm is tested on two 2D synthetic salt models, namely, the Sigsbee 2A model and a modified SEG Advanced Modeling Program (SEAM) Phase I model while fixing the top of the salt. We determine the efficiency of the VFSA inversion and imaging improvements from the level set FWI approach and evaluate a few sources of uncertainty in the estimation of salt shapes.},
	author = {Datta, Debanjan and Sen, Mrinal K. and Liu, Faqi and Morton, Scott},
	doi = {10.1190/geo2018-0175.1},
	file = {:C\:/Users/VIKAS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Datta et al. - 2019 - Full-waveform inversion of salt models using shape optimization and simulated annealing(3).pdf:pdf},
	issn = {19422156},
	journal = {Geophysics},
	keywords = {2D,acoustic,full-waveform inversion,optimization,salt},
	mendeley-groups = {global_optimization},
	number = {5},
	pages = {R793--R804},
	title = {{Full-waveform inversion of salt models using shape optimization and simulated annealing}},
	volume = {84},
	year = {2019}
}

@article{Mazzotti2016,
	abstract = {Full-waveform inversion (FWI) tries to estimate velocity models of the subsurface with improved accuracy and resolution compared to conventional methods. To be successful, it needs input data that is rich in low frequencies and possibly characterized by long source-to-receiver offsets. The correct solution of the inverse problem by means of local methods is facilitated if the starting model lies in the "valley" of the cost-function global minimum. We explore the possibility of relaxing this requirement by using genetic algorithms, a stochastic optimization method, as the driver of the FWI (GA FWI). However, stochastic methods are affected by the "curse of dimensionality," meaning that they require huge and sometimes even unaffordable computer resources for inverse problems with many unknowns and costly forward modeling. Therefore, we need to adopt proper stratagems in the inversion and limit our goal to the estimation of a velocity macromodel that is of a model with only the long-wavelength velocity structures, which could eventually act as the starting model for a local, higher-resolution gradient-based inversion. To this end, in the GA FWI we parametrize the subsurface with two grids: (1) a coarse grid with widely spaced nodes, that is unknowns, for the inversion, and (2) a fine grid with shorter spacing for the modeling. As a side result, we can also have an estimate of the uncertainty at the solution nodes of the grid. The approach we discuss is 2D acoustic in the time domain, with finite difference forward modeling. The examples we show refer to the Marmousi model and to a marine field data set.},
	author = {Mazzotti, Alfredo and Bienati, Nicola and Stucchi, Eusebio and Tognarelli, Andrea and Aleardi, Mattia and Sajeva, Angelo},
	doi = {10.1190/tle35121068.1},
	file = {:D\:/Vikas/research_papers/global optimization/tle35121068.1.pdf:pdf},
	issn = {19383789},
	journal = {Leading Edge},
	mendeley-groups = {global_optimization},
	number = {12},
	pages = {1068--1075},
	title = {{Two-grid genetic algorithm full-waveform inversion}},
	volume = {35},
	year = {2016}
}

@article{ktran2012,
	abstract = {A technique is presented to invert full waveforms using a genetic algorithm. The inversion scheme is based on a finite-difference solution of the 2-D elastic wave equation in the time-distance domain. The strength of this approach is the ability to generate all possible wave types (body waves and surface waves, etc.) and thus to simulate complex seismic wavefields that are then compared with observed data to infer subsurface properties. The capability of this inversion technique is tested with both synthetic and real experimental data sets. The inversion results from synthetic data show the ability of characterizing both low- and high-velocity layers, and the inversion results from real data are generally consistent with crosshole, SPT N-value, and material log results, including the identification of a buried low-velocity layer. Based upon the cases presented, coupling of global optimization with full waveforms is computationally practical, as the results presented herein were all achieved in about two hours of computer time on a standard laptop computer.},
	author = {Tran, Khiem T. and Hiltunen, Dennis R.},
	doi = {10.2113/jeeg17.4.197},
	file = {:D\:/Vikas/research_papers/global optimization/tran-hiltunen-2012-one-dimensional-inversion-of-full-waveforms-using-a-genetic-algorithm.pdf:pdf},
	issn = {1083-1363},
	journal = {Journal of Environmental and Engineering Geophysics},
	mendeley-groups = {global_optimization},
	number = {4},
	pages = {197--213},
	title = {{One-Dimensional Inversion of Full Waveforms using a Genetic Algorithm}},
	volume = {17},
	year = {2012}
}

@article{Zeng2011,
	abstract = {Conventional surface wave inversion for shallow shear (S)-wave velocity relies on the generation of dispersion curves of Rayleigh waves. This constrains the method to only laterally homogeneous (or very smooth laterally heterogeneous) earth models. Waveform inversion directly fits waveforms on seismograms, hence, does not have such a limitation. Waveforms of Rayleigh waves are highly related to S-wave velocities. By inverting the waveforms of Rayleigh waves on a near-surface seismogram, shallow S-wave velocities can be estimated for earth models with strong lateral heterogeneity. We employ genetic algorithm (GA) to perform waveform inversion of Rayleigh waves for S-wave velocities. The forward problem is solved by finite-difference modeling in the time domain. The model space is updated by generating offspring models using GA. Final solutions can be found through an iterative waveform-fitting scheme. Inversions based on synthetic records show that the S-wave velocities can be recovered successfully with errors no more than 10% for several typical near-surface earth models. For layered earth models, the proposed method can generate one-dimensional S-wave velocity profiles without the knowledge of initial models. For earth models containing lateral heterogeneity in which case conventional dispersion-curve-based inversion methods are challenging, it is feasible to produce high-resolution S-wave velocity sections by GA waveform inversion with appropriate priori information. The synthetic tests indicate that the GA waveform inversion of Rayleigh waves has the great potential for shallow S-wave velocity imaging with the existence of strong lateral heterogeneity. {\textcopyright} 2011 Elsevier B.V.},
	author = {Zeng, Chong and Xia, Jianghai and Miller, Richard D. and Tsoflias, Georgios P.},
	doi = {10.1016/j.jappgeo.2011.09.028},
	file = {:D\:/Vikas/research_papers/global optimization/1-s2.0-S0926985111002308-main.pdf:pdf},
	issn = {09269851},
	journal = {Journal of Applied Geophysics},
	keywords = {Finite difference,Genetic algorithm,Lateral heterogeneity,Rayleigh waves,Waveform inversion},
	mendeley-groups = {global_optimization},
	number = {4},
	pages = {648--655},
	title = {{Feasibility of waveform inversion of Rayleigh waves for shallow shear-wave velocity using a genetic algorithm}},
	volume = {75},
	year = {2011}
}

@article{Aleardi,
	author = {Aleardi, Mattia and Mazzotti, Alfredo},
	title = {1D elastic full-waveform inversion and uncertainty estimation by means of a hybrid genetic algorithm–Gibbs sampler approach},
	journal = {Geophysical Prospecting},
	volume = {65},
	number = {1},
	pages = {64-85},
	keywords = {Full-waveform inversion, Elastic, Stochastic},
	doi = {https://doi.org/10.1111/1365-2478.12397},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1365-2478.12397},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1365-2478.12397},
	abstract = {ABSTRACT Stochastic optimization methods, such as genetic algorithms, search for the global minimum of the misfit function within a given parameter range and do not require any calculation of the gradients of the misfit surfaces. More importantly, these methods collect a series of models and associated likelihoods that can be used to estimate the posterior probability distribution. However, because genetic algorithms are not a Markov chain Monte Carlo method, the direct use of the genetic-algorithm-sampled models and their associated likelihoods produce a biased estimation of the posterior probability distribution. In contrast, Markov chain Monte Carlo methods, such as the Metropolis–Hastings and Gibbs sampler, provide accurate posterior probability distributions but at considerable computational cost. In this paper, we use a hybrid method that combines the speed of a genetic algorithm to find an optimal solution and the accuracy of a Gibbs sampler to obtain a reliable estimation of the posterior probability distributions. First, we test this method on an analytical function and show that the genetic algorithm method cannot recover the true probability distributions and that it tends to underestimate the true uncertainties. Conversely, combining the genetic algorithm optimization with a Gibbs sampler step enables us to recover the true posterior probability distributions. Then, we demonstrate the applicability of this hybrid method by performing one-dimensional elastic full-waveform inversions on synthetic and field data. We also discuss how an appropriate genetic algorithm implementation is essential to attenuate the “genetic drift” effect and to maximize the exploration of the model space. In fact, a wide and efficient exploration of the model space is important not only to avoid entrapment in local minima during the genetic algorithm optimization but also to ensure a reliable estimation of the posterior probability distributions in the subsequent Gibbs sampler step.},
	year = {2017}
}

@article{Yang2017,
	abstract = {In order to improve the fine structure inversion ability of igneous rocks for the exploration of underlying strata, based on particle swarm optimization (PSO), we have developed a method for seismic wave impedance inversion. Through numerical simulation, we tested the effects of different algorithm parameters and different model parameterization methods on PSO wave impedance inversion, and analyzed the characteristics of PSO method. Under the conclusions drawn from numerical simulation, we propose the scheme of combining a cross-moving strategy based on a divided block model and high-frequency filtering technology for PSO inversion. By analyzing the inversion results of a wedge model of a pitchout coal seam and a coal coking model with igneous rock intrusion, we discuss the vertical and horizontal resolution, stability and reliability of PSO inversion. Based on the actual seismic and logging data from an igneous area, by taking a seismic profile through wells as an example, we discuss the characteristics of three inversion methods, including model-based wave impedance inversion, multi-attribute seismic inversion based on probabilistic neural network (PNN) and wave impedance inversion based on PSO. And we draw the conclusion that the inversion based on PSO method has a better result for this igneous area.},
	author = {Yang, Haijun and Xu, Yongzhong and Peng, Gengxin and Yu, Guiping and Chen, Meng and Duan, Wensheng and Zhu, Yongfeng and Cui, Yongfu and Wang, Xingjun},
	doi = {10.1016/j.ijmst.2017.01.019},
	file = {:D\:/Vikas/research_papers/global optimization/1-s2.0-S2095268617300654-main.pdf:pdf},
	issn = {20952686},
	journal = {International Journal of Mining Science and Technology},
	keywords = {Igneous rocks,Model-based inversion,Particle swarm optimization,Probabilistic neutral network,Seismic inversion},
	mendeley-groups = {global_optimization},
	number = {2},
	pages = {349--357},
	publisher = {China University of Mining & Technology},
	title = {{Particle swarm optimization and its application to seismic inversion of igneous rocks}},
	url = {http://dx.doi.org/10.1016/j.ijmst.2017.01.019},
	volume = {27},
	year = {2017}
}

@article{Shaw2007,
	abstract = {Particle swarm optimization (PSO) is a global optimization strategy that simulates the social behavior observed in a flock (swarm) of birds searching for food. A simple search strategy in PSO guides the algorithm toward the best solution through constant updating of the cognitive knowledge and social behavior of the particles in the swarm. To evaluate the applicability of PSO to inversion of geophysical data, we inverted three noise-corrupted synthetic sounding data sets over a multilayered 1D earth model by using DC, induced polarization (IP), and magnetotelluric (MT) methods. The results show that acceptable solutions can be obtained with a swarm of about 300 particles and that convergence occurs in less than 100 iterations. The time required to execute a PSO algorithm is comparable to that of a genetic algorithm (GA). Similarly, the models estimated from PSO and GA are close to the true solutions. Whereas a ridge regression (RR) algorithm converges in four to eight iterations, it yields satisfactory results only when the initial model is very close to the true model. Models estimated from PSO explain observed, vertical electric sounding (VES) and MT data, from Bhiwani district, Haryana, India, and the Chottanagpur gneissic complex, Dhanbad, India. The results are consistent with RR and GA inversions. {\textcopyright} 2007 Society of Exploration Geophysicists.},
	author = {Shaw, Ranjit and Srivastava, Shalivahan},
	doi = {10.1190/1.2432481},
	file = {:D\:/Vikas/research_papers/global optimization/shaw-srivastava-2007-particle-swarm-optimization-a-new-tool-to-invert-geophysical-data.pdf:pdf},
	issn = {00168033},
	journal = {Geophysics},
	keywords = {Genetic algorithms,Geomagnetism,Geophysical techniques,Terrestrial electricity},
	mendeley-groups = {global_optimization},
	number = {2},
	title = {{Particle swarm optimization: A new tool to invert geophysical data}},
	volume = {72},
	year = {2007}
}

@article{Ding2015,
	abstract = {Inversion is a critical and challenging task in geophysical research. Geophysical inversion can be formulated as an optimization problem to find the best parameters whose forward synthesis data most fit the observed data. The inverse problems are usually highly non-linear, multi-modal as well as ill-posed, so conventional optimization algorithms cannot handle it very efficiently. In the past decades, genetic algorithm (GA) and its many variants are widely applied to inverse problems and achieve great success. Swarm intelligence algorithms are a family of global optimizers inspired by swarm phenomena in nature, and have shown better performance than GA for diverse optimization problems. However, swarm intelligence algorithms are not utilized for geophysical inversion problems until recently and only limited number of works are reported. In this paper, we try to apply two swarm intelligence algorithms, Particle Swarm Optimization (PSO) and Fireworks Algorithm (FWA), to the regional seismic waveform inversion. To explore the advantages and disadvantages of swarm intelligence algorithms over GA, synthetic experiments are conducted by using these two swarm intelligence algorithm and several GA variants as well as Differential Evolution (DE). The experimental results show that, both swarm intelligence algorithms outperform the widely used GA, DE, and the models estimated by swarm intelligence algorithms are closer to the true solution. The promising results imply that swarm intelligence algorithms are a potentially more powerful tool for inversion problems.},
	author = {Ding, Ke and Chen, Yanyang and Wang, Yanbin and Tan, Ying},
	doi = {10.1109/CEC.2015.7257030},
	file = {:D\:/Vikas/research_papers/global optimization/Regional_seismic_waveform_inversion_using_swarm_intelligence_algorithms.pdf:pdf},
	isbn = {9781479974924},
	journal = {2015 IEEE Congress on Evolutionary Computation, CEC 2015 - Proceedings},
	mendeley-groups = {global_optimization},
	pages = {1235--1241},
	publisher = {IEEE},
	title = {{Regional seismic waveform inversion using swarm intelligence algorithms}},
	year = {2015}
}

@article{Kaplanvural2020,
	abstract = {This study investigates the identification of buried materials from ground-penetrating radar (GPR) signals by applying Particle Swarm Optimization (PSO) method for the inversion of individual traces. Interpretation of GPR data can be carried out either by applying some basic processing steps to raw data or by inverting GPR data. However, for obtaining more specific information about the buried object, some more advanced algorithms are required. In this study, the PSO, which has been used to solve many engineering problems, is utilized to invert the GPR traces for detecting various types of buried plastic pipe fillings. Firstly, we confirmed the applicability of PSO to GPR traces using numerical modeling. Then, the data acquired over buried pipe filling materials (air, water ice) were evaluated experimentally by the proposed method. Determination of the filling material is one of the most popular problems of shallow pipe exploration by GPR. The inversion process resulted in good data fit between observed and calculated traces for air-filled, water-filled, and ice-filled pipe. The estimated dielectric properties including relative dielectric permittivity, conductivity, and relative magnetic permeability values were in the range of the corresponding parameter values in the literature at the end of inversion for each model. These results show that the PSO method applied to GPR data can distinguish plastic pipe contents. Moreover, the results suggest that PSO can be used for the quantitative interpretation of GPR data.},
	author = {Kaplanvural, Ismail and Pekşen, Ertan and {\"{O}}zkap, Kerem},
	doi = {10.1016/j.jappgeo.2020.104157},
	file = {:D\:/Vikas/research_papers/global optimization/1-s2.0-S0926985120305401-main.pdf:pdf},
	issn = {09269851},
	journal = {Journal of Applied Geophysics},
	keywords = {Ground-penetrating Radar,Inversion,Non-destructive Evaluation,Particle Swarm Optimization,Pipes},
	mendeley-groups = {global_optimization},
	title = {{1D waveform inversion of GPR trace by particle swarm optimization}},
	volume = {181},
	year = {2020}
}

@article{Fernandez-Martinez2010,
	abstract = {We apply different particle swarm optimizers (PSO) to a history matching problem for the synthetic Stanford VI sand-and-shale reservoir. The ill-posed character of this inverse problem is attenuated by reducing the model complexity using a Spatial Principal Component base and by combining as observables flow production measurements and cross-well seismic data. Additionally the inverse problem is solved in a stochastic framework searching for the family of reservoir models that equally fit the data. We show that PSO algorithms have a very good convergence rate and in addition provide approximate measures of uncertainty around the optimum facies model. The uncertainty estimation, although it is a proxy for the true posterior distribution of model parameters, allow us to perform risk analysis..},
	author = {Fern{\'{a}}ndez-Mart{\'{i}}nez, Juan Luis and Mukerji, Tapan and Garc{\'{i}}a-Gonzalo, Esperanza and Suman, Amit},
	doi = {10.1190/1.3513319},
	file = {:D\:/Vikas/research_papers/global optimization/fern{\'{a}}ndez-mart{\'{i}}nez-et-al-2012-reservoir-characterization-and-inversion-uncertainty-via-a-family-of-particle-swarm.pdf:pdf},
	isbn = {9781617389801},
	journal = {Society of Exploration Geophysicists International Exposition and 80th Annual Meeting 2010, SEG 2010},
	mendeley-groups = {global_optimization},
	number = {1},
	pages = {2334--2339},
	title = {{Reservoir characterization and inversion uncertainty via a family of particle swarm optimizers}},
	volume = {77},
	year = {2010}
}

@article{Fern2010,
	abstract = {Waterflowin the subsoil generates electrical currents mea- surable at the ground surface with the self-potential method. These measured potentials, which result from hy- droelectric coupling, are called streaming potentials and are well correlated with the geometry of the water table. The par- ticle swarm algorithm can be used to estimate the water-table elevation from SP data measured at the ground surface. The basic idea behind particle swarm optimization  is that each model searches the model space according to its misfit history and the misfit of the other models particles of the swarm. PSO is a simple, robust, and versatile algorithm with a very good convergence rate typically before 3000 forward runs, and it can explore a large model space without being time consuming. Based on samples gathered in a low-misfit area, we have computed a fast approximation of the posterior distribution of the water table, the electrokinetic coupling constant, and the reference hydraulic head. Although PSO is a stochastic search technique, our convergence results, based on the stability of particle trajectories, specify clear criteria to tunePSOparameters.},
	author = {Fern, Juan Luis and Garc, Esperanza},
	file = {:D\:/Vikas/research_papers/global optimization/fern{\'{a}}ndez-mart{\'{i}}nez-et-al-2010-particle-swarm-optimization-applied-to-solving-and-appraising-the-streaming-potential.pdf:pdf},
	journal = {Geophysics},
	mendeley-groups = {global_optimization},
	number = {4},
	title = {{Appraising the Streaming-Potential Inverse Problem}},
	volume = {75},
	year = {2010}
}

@article{Sajeva2017,
	abstract = {We compare the performances of four stochastic optimisation methods using four analytic objective functions and two highly non-linear geophysical optimisation problems: one-dimensional elastic full-waveform inversion and residual static computation. The four methods we consider, namely, adaptive simulated annealing, genetic algorithm, neighbourhood algorithm, and particle swarm optimisation, are frequently employed for solving geophysical inverse problems. Because geophysical optimisations typically involve many unknown model parameters, we are particularly interested in comparing the performances of these stochastic methods as the number of unknown parameters increases. The four analytic functions we choose simulate common types of objective functions encountered in solving geophysical optimisations: a convex function, two multi-minima functions that differ in the distribution of minima, and a nearly flat function. Similar to the analytic tests, the two seismic optimisation problems we analyse are characterised by very different objective functions. The first problem is a one-dimensional elastic full-waveform inversion, which is strongly ill-conditioned and exhibits a nearly flat objective function, with a valley of minima extended along the density direction. The second problem is the residual static computation, which is characterised by a multi-minima objective function produced by the so-called cycle-skipping phenomenon. According to the tests on the analytic functions and on the seismic data, genetic algorithm generally displays the best scaling with the number of parameters. It encounters problems only in the case of irregular distribution of minima, that is, when the global minimum is at the border of the search space and a number of important local minima are distant from the global minimum. The adaptive simulated annealing method is often the best-performing method for low-dimensional model spaces, but its performance worsens as the number of unknowns increases. The particle swarm optimisation is effective in finding the global minimum in the case of low-dimensional model spaces with few local minima or in the case of a narrow flat valley. Finally, the neighbourhood algorithm methodis competitive with the other methods only for low-dimensional model spaces; its performance sensibly worsens in the case of multi-minima objective functions.},
	author = {Sajeva, Angelo and Aleardi, Mattia and Galuzzi, Bruno and Stucchi, Eusebio and Spadavecchia, Emmanuel and Mazzotti, Alfredo},
	doi = {10.1111/1365-2478.12532},
	file = {:home/vikas/Desktop/papers/Geophysical Prospecting - 2017 - Sajeva - Comparing the performances of four stochastic optimisation methods using analytic.pdf:pdf},
	issn = {13652478},
	journal = {Geophysical Prospecting},
	keywords = {Optimisation,Stochastic},
	mendeley-groups = {global{\_}optimization},
	number = {Special Issue  1},
	pages = {322--346},
	title = {{Comparing the performances of four stochastic optimisation methods using analytic objective functions, 1D elastic full-waveform inversion, and residual static computation}},
	volume = {65},
	year = {2017}
}

@article{Sajeva2017,
	abstract = {We compare the performances of four stochastic optimisation methods using four analytic objective functions and two highly non-linear geophysical optimisation problems: one-dimensional elastic full-waveform inversion and residual static computation. The four methods we consider, namely, adaptive simulated annealing, genetic algorithm, neighbourhood algorithm, and particle swarm optimisation, are frequently employed for solving geophysical inverse problems. Because geophysical optimisations typically involve many unknown model parameters, we are particularly interested in comparing the performances of these stochastic methods as the number of unknown parameters increases. The four analytic functions we choose simulate common types of objective functions encountered in solving geophysical optimisations: a convex function, two multi-minima functions that differ in the distribution of minima, and a nearly flat function. Similar to the analytic tests, the two seismic optimisation problems we analyse are characterised by very different objective functions. The first problem is a one-dimensional elastic full-waveform inversion, which is strongly ill-conditioned and exhibits a nearly flat objective function, with a valley of minima extended along the density direction. The second problem is the residual static computation, which is characterised by a multi-minima objective function produced by the so-called cycle-skipping phenomenon. According to the tests on the analytic functions and on the seismic data, genetic algorithm generally displays the best scaling with the number of parameters. It encounters problems only in the case of irregular distribution of minima, that is, when the global minimum is at the border of the search space and a number of important local minima are distant from the global minimum. The adaptive simulated annealing method is often the best-performing method for low-dimensional model spaces, but its performance worsens as the number of unknowns increases. The particle swarm optimisation is effective in finding the global minimum in the case of low-dimensional model spaces with few local minima or in the case of a narrow flat valley. Finally, the neighbourhood algorithm methodis competitive with the other methods only for low-dimensional model spaces; its performance sensibly worsens in the case of multi-minima objective functions.},
	author = {Sajeva, Angelo and Aleardi, Mattia and Galuzzi, Bruno and Stucchi, Eusebio and Spadavecchia, Emmanuel and Mazzotti, Alfredo},
	doi = {10.1111/1365-2478.12532},
	file = {:home/vikas/Desktop/papers/Geophysical Prospecting - 2017 - Sajeva - Comparing the performances of four stochastic optimisation methods using analytic.pdf:pdf},
	issn = {13652478},
	journal = {Geophysical Prospecting},
	keywords = {Optimisation,Stochastic},
	mendeley-groups = {global{\_}optimization},
	number = {Special Issue  1},
	pages = {322--346},
	title = {{Comparing the performances of four stochastic optimisation methods using analytic objective functions, 1D elastic full-waveform inversion, and residual static computation}},
	volume = {65},
	year = {2017}
}

@article{Sambridge1992,
	abstract = {Recently a new class of methods, to solve non‐linear optimization problems, has generated considerable interest in the field of Artificial Intelligence. These methods, known as genetic algorithms, are able to solve highly non‐linear and non‐local optimization problems and belong to the class of global optimization techniques, which includes Monte Carlo and Simulated Annealing methods. Unlike local techniques, such as damped least squares or conjugate gradients, genetic algorithms avoid all use of curvature information on the objective function. This means that they do not require any derivative information and therefore one can use any type of misfit function equally well. Most iterative methods work with a single model and find improvements by perturbing it in some fashion. Genetic algorithms, however, work with a group of models simultaneously and use stochastic processes to guide the search for an optimal solution. Both Simulated Annealing and genetic algorithms are modelled on natural optimization systems. Simulated Annealing uses an analogy with thermodynamics; genetic algorithms have an analogy with biological evolution. This evolution leads to an efficient exchange of information between all models encountered, and allows the algorithm to rapidly assimilate and exploit the information gained to find better data fitting models. To illustrate the power of genetic algorithms compared to Monte Carlo, we consider a simple multidimensional quadratic optimization problem and show that its relative efficiency increases dramatically as the number of unknowns is increased. As an example of their use in a geophysical problem with real data we consider the non‐linear inversion of marine seismic refraction waveforms. The results show that genetic algorithms are inherently superior to random search techniques and can also perform better than iterative matrix inversion which requires a good starting model. This is primarily because genetic algorithms are able to combine both local and global search mechanisms into a single efficient method. Since many forward and inverse problems involve solving an optimization problem, we expect that the genetic approach will find applications in many other geophysical problems; these include seismic ray tracing, earthquake location, non‐linear data fitting and, possibly seismic tomography. Copyright {\textcopyright} 1992, Wiley Blackwell. All rights reserved},
	author = {Sambridge, Malcolm and Drijkoningen, Guy},
	doi = {10.1111/j.1365-246X.1992.tb00100.x},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sambridge, Drijkoningen - 1992 - Genetic algorithms in seismic waveform inversion.pdf:pdf},
	issn = {1365246X},
	journal = {Geophysical Journal International},
	keywords = {genetic algorithms,global optimization,waveform inversion},
	mendeley-groups = {global{\_}optimization},
	number = {2},
	pages = {323--342},
	title = {{Genetic algorithms in seismic waveform inversion}},
	volume = {109},
	year = {1992}
}

@article{Ding2015,
	abstract = {Inversion is a critical and challenging task in geophysical research. Geophysical inversion can be formulated as an optimization problem to find the best parameters whose forward synthesis data most fit the observed data. The inverse problems are usually highly non-linear, multi-modal as well as ill-posed, so conventional optimization algorithms cannot handle it very efficiently. In the past decades, genetic algorithm (GA) and its many variants are widely applied to inverse problems and achieve great success. Swarm intelligence algorithms are a family of global optimizers inspired by swarm phenomena in nature, and have shown better performance than GA for diverse optimization problems. However, swarm intelligence algorithms are not utilized for geophysical inversion problems until recently and only limited number of works are reported. In this paper, we try to apply two swarm intelligence algorithms, Particle Swarm Optimization (PSO) and Fireworks Algorithm (FWA), to the regional seismic waveform inversion. To explore the advantages and disadvantages of swarm intelligence algorithms over GA, synthetic experiments are conducted by using these two swarm intelligence algorithm and several GA variants as well as Differential Evolution (DE). The experimental results show that, both swarm intelligence algorithms outperform the widely used GA, DE, and the models estimated by swarm intelligence algorithms are closer to the true solution. The promising results imply that swarm intelligence algorithms are a potentially more powerful tool for inversion problems.},
	author = {Ding, Ke and Chen, Yanyang and Wang, Yanbin and Tan, Ying},
	doi = {10.1109/CEC.2015.7257030},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - 2015 - Regional seismic waveform inversion using swarm intelligence algorithms.pdf:pdf},
	isbn = {9781479974924},
	journal = {2015 IEEE Congress on Evolutionary Computation, CEC 2015 - Proceedings},
	mendeley-groups = {global{\_}optimization},
	pages = {1235--1241},
	publisher = {IEEE},
	title = {{Regional seismic waveform inversion using swarm intelligence algorithms}},
	year = {2015}
}

@article{Mojica2019,
	author = {Mojica, Oscar and Nogueira, Peterson and Santana, Rodrigo and Relevo, Daniel},
	doi = {10.22564/16cisbgf2019.078},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mojica et al. - 2019 - Building starting models for full-waveform inversion using global optimization methods - A comparison between Par.pdf:pdf},
	mendeley-groups = {FWI,global{\_}optimization},
	pages = {1--4},
	title = {{Building starting models for full-waveform inversion using global optimization methods - A comparison between Particle swarm optimization and genetic algorithm}},
	year = {2019}
}

@article{Sajeva2017,
	abstract = {We compare the performances of four stochastic optimisation methods using four analytic objective functions and two highly non-linear geophysical optimisation problems: one-dimensional elastic full-waveform inversion and residual static computation. The four methods we consider, namely, adaptive simulated annealing, genetic algorithm, neighbourhood algorithm, and particle swarm optimisation, are frequently employed for solving geophysical inverse problems. Because geophysical optimisations typically involve many unknown model parameters, we are particularly interested in comparing the performances of these stochastic methods as the number of unknown parameters increases. The four analytic functions we choose simulate common types of objective functions encountered in solving geophysical optimisations: a convex function, two multi-minima functions that differ in the distribution of minima, and a nearly flat function. Similar to the analytic tests, the two seismic optimisation problems we analyse are characterised by very different objective functions. The first problem is a one-dimensional elastic full-waveform inversion, which is strongly ill-conditioned and exhibits a nearly flat objective function, with a valley of minima extended along the density direction. The second problem is the residual static computation, which is characterised by a multi-minima objective function produced by the so-called cycle-skipping phenomenon. According to the tests on the analytic functions and on the seismic data, genetic algorithm generally displays the best scaling with the number of parameters. It encounters problems only in the case of irregular distribution of minima, that is, when the global minimum is at the border of the search space and a number of important local minima are distant from the global minimum. The adaptive simulated annealing method is often the best-performing method for low-dimensional model spaces, but its performance worsens as the number of unknowns increases. The particle swarm optimisation is effective in finding the global minimum in the case of low-dimensional model spaces with few local minima or in the case of a narrow flat valley. Finally, the neighbourhood algorithm methodis competitive with the other methods only for low-dimensional model spaces; its performance sensibly worsens in the case of multi-minima objective functions.},
	author = {Sajeva, Angelo and Aleardi, Mattia and Galuzzi, Bruno and Stucchi, Eusebio and Spadavecchia, Emmanuel and Mazzotti, Alfredo},
	doi = {10.1111/1365-2478.12532},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sajeva et al. - 2017 - Comparing the performances of four stochastic optimisation methods using analytic objective functions, 1D elastic.pdf:pdf},
	issn = {13652478},
	journal = {Geophysical Prospecting},
	keywords = {Optimisation,Stochastic},
	mendeley-groups = {global{\_}optimization},
	number = {Special Issue  1},
	pages = {322--346},
	title = {{Comparing the performances of four stochastic optimisation methods using analytic objective functions, 1D elastic full-waveform inversion, and residual static computation}},
	volume = {65},
	year = {2017}
}

@article{Aleardi2017,
	abstract = {Stochastic optimization methods, such as genetic algorithms, search for the global minimum of the misfit function within a given parameter range and do not require any calculation of the gradients of the misfit surfaces. More importantly, these methods collect a series of models and associated likelihoods that can be used to estimate the posterior probability distribution. However, because genetic algorithms are not a Markov chain Monte Carlo method, the direct use of the genetic-algorithm-sampled models and their associated likelihoods produce a biased estimation of the posterior probability distribution. In contrast, Markov chain Monte Carlo methods, such as the Metropolis–Hastings and Gibbs sampler, provide accurate posterior probability distributions but at considerable computational cost. In this paper, we use a hybrid method that combines the speed of a genetic algorithm to find an optimal solution and the accuracy of a Gibbs sampler to obtain a reliable estimation of the posterior probability distributions. First, we test this method on an analytical function and show that the genetic algorithm method cannot recover the true probability distributions and that it tends to underestimate the true uncertainties. Conversely, combining the genetic algorithm optimization with a Gibbs sampler step enables us to recover the true posterior probability distributions. Then, we demonstrate the applicability of this hybrid method by performing one-dimensional elastic full-waveform inversions on synthetic and field data. We also discuss how an appropriate genetic algorithm implementation is essential to attenuate the “genetic drift” effect and to maximize the exploration of the model space. In fact, a wide and efficient exploration of the model space is important not only to avoid entrapment in local minima during the genetic algorithm optimization but also to ensure a reliable estimation of the posterior probability distributions in the subsequent Gibbs sampler step.},
	author = {Aleardi, Mattia and Mazzotti, Alfredo},
	doi = {10.1111/1365-2478.12397},
	file = {:home/vikas/Desktop/papers/Geophysical Prospecting - 2016 - Aleardi - 1D elastic full‐waveform inversion and uncertainty estimation by means of a.pdf:pdf},
	issn = {13652478},
	journal = {Geophysical Prospecting},
	keywords = {Elastic,Full-waveform inversion,Stochastic},
	mendeley-groups = {global{\_}optimization},
	number = {1},
	pages = {64--85},
	title = {{1D elastic full-waveform inversion and uncertainty estimation by means of a hybrid genetic algorithm–Gibbs sampler approach}},
	volume = {65},
	year = {2017}
}

@article{Tarantola1986,
	abstract = {Three parameters are needed to describe a perfectly elastic, isotropic Earth. These may be the density $\rho$(x) and the Lame's parameters $\gamma$(x) and $\mu$(x), or the density $\rho$(x) and the P-wave and S-wave velocities $\alpha$(x) and $\beta$(x). The choice of parameters is not neutral in the sense that although theoretically equivalent, if they are not adequately chosen the numerical algorithms used in the inversion can be very inefficient. In the long spatial wavelengths of the model, adequate parameters are the P-wave and S-wave velocities, while in the short spatial wavelengths, P-wave impedance, 5-wave impedance, and density are adequate. The problem of inversion of waveforms is highly nonlinear for the long spatial wavelengths of the velocities, while it is reasonably linear for the short spatial wavelengths of the impedances and density. Furthermore, this parameterization defines a highly hierarchical problem: the long spatial wavelengths of the P-wave velocity and short spatial wavelengths of the P-wave impedance are much more important parameters than their counterparts for S-waves (in terms of interpreting observed amplitudes), and the latter are much more important than the density. This suggests solution of the general inverse problem (which must involve all the parameters) optimizing first for the P-wave velocity and impedance, then for the 5-wave velocity and impedance, and finally for density. As a by-product of the method proposed here, a generalization to the elastic case of the equations of multioffset acoustic migration is obtained.},
	author = {Tarantola, Albert},
	doi = {10.1190/1.1893017},
	file = {:home/vikas/Downloads/tarantola-2012-a-strategy-for-nonlinear-elastic-inversion-of-seismic-reflection-data.pdf:pdf},
	journal = {1986 SEG Annual Meeting, SEG 1986},
	number = {10},
	pages = {527--530},
	title = {{A strategy for nonlinear elastic inversion of seismic reflection data}},
	volume = {51},
	year = {1986}
}


@article{Schuster2017,
	abstract = {Fundamentals -- Deconvolution -- Velocity analysis, statics corrections, and stacking -- Migration -- Imaging beneath comples structures -- 3-D seismic exploration -- Slant stack and applications -- Special topics.},
	author = {Schuster, Gerard T.},
	doi = {10.1190/1.9781560803423},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schuster - 2017 - Seismic Inversion.pdf:pdf},
	journal = {Seismic Inversion},
	mendeley-groups = {books,FWI},
	title = {{Seismic Inversion}},
	year = {2017}
}

@article{Virieux2009a,
	abstract = {Full-waveform inversion (FWI) is a challenging data-fitting procedure based on full-wavefield modeling to extract quantitative information from seismograms. High-resolution imaging at half the propagated wavelength is expected. Recent advances in high-performance computing and multifold/multicomponent wide-aperture and wide-azimuth acquisitions make 3D acoustic FWI feasible today. Key ingredients of FWI are an efficient forward-modeling engine and a local differential approach, in which the gradient and the Hessian operators are efficiently estimated. Local optimization does not, however, prevent convergence of the misfit function toward local minima because of the limited accuracy of the starting model, the lack of low frequencies, the presence of noise, and the approximate modeling of thewave-physics complexity. Different hierarchical multiscale strategies are designed to mitigate the nonlinearity and ill-posedness of FWI by incorporating progressively shorter wavelengths in the parameter space. Synthetic and real-data case studies address reconstructing various parameters, from P and S velocities to density, anisotropy, and attenuation. This review attempts to illuminate the state of the art of FWI. Crucial jumps, however, remain necessary to make it as popular as migration techniques. The challenges can be categorized as (1) building accurate starting models with automatic procedures and/or recording low frequencies, (2) defining new minimization criteria to mitigate the sensitivity of FWI to amplitude errors and increasing the robustness of FWI when multiple parameter classes are estimated, and (3) improving computational efficiency by data-compression techniques to make 3D elastic FWI feasible. {\textcopyright} 2009 Society of Exploration Geophysicists.},
	author = {Virieux, J. and Operto, S.},
	doi = {10.1190/1.3238367},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Virieux, Operto - 2009 - An overview of full-waveform inversion in exploration geophysics.pdf:pdf},
	issn = {00168033},
	journal = {Geophysics},
	mendeley-groups = {books/finite difference,numerical{\_}modelling},
	number = {6},
	title = {{An overview of full-waveform inversion in exploration geophysics}},
	volume = {74},
	year = {2009}
}

@article{Liu2017,
	abstract = {In fullwaveforminversion (FWI) with the least-squares (L2) norm, the direct amplitude matching is never perfect and the accurate estimation of the seismic source strength is not always available. In contrast, the normalized zero-lag cross-correlation objective function relaxes on the amplitude constraints and emphasizes the phase information when measuring the closeness between the simulated and observed data. This FWI method becomes insensitive to differences in amplitude. Based on this property, we investigate the effectiveness and robustness of FWI with the normalized zero-lag cross-correlation function (CFWI) against the noise and unpredictable amplitude of the data that cannot be modelled by the wavefield extrapolation operator. The effectiveness is firstly tested by noise-free data and data contaminated by Gaussian white noise. In addition, CFWI can invert the data set with incorrect source strength when compared with the L2 norm. Moreover, the data set with incorrect source signature illustrates that CFWI is slightly more insensitive to the error in source signature than the L2 norm. However, a source inversion is still needed when the source signature is severely erroneous. With non-Gaussian noise data, such as contaminated by strong ground motion noise and even by spike-type noise, CFWI provides a comparable result with that of the robust Huber norm. Numerical experiments with non-Gaussian noise also indicate that CFWI can suppress noise in data to produce clearer images when compared with the Huber norm. Besides, CFWI is free of the threshold criterion that controls the transition between the L2 and L1 norms used with the Huber and Hybrid norms and therefore free from tedious trial-and-error tests. Several numerical examples support that CFWI is an alternative and reliable inversion method. However, a numerical test with a 1-D initial model confirms that CFWI is more sensitive to the cycle-skipping problem caused by less-accurate initial velocity model than the L2 norm, which is due to the wrong matched events contributing to spurious local minima of the objective function of CFWI, but to an increase in the objective function used with the L2 norm.},
	author = {Liu, Youshan and Teng, Jiwen and Xu, Tao and Wang, Yanghua and Liu, Qinya and Badal, Jos{\'{e}}},
	doi = {10.1093/gji/ggw485},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2017 - Robust time-domain full waveform inversion with normalized zero-lag cross-correlation objective function.pdf:pdf},
	issn = {1365246X},
	journal = {Geophysical Journal International},
	keywords = {Inverse theory,Seismology,Waveform inversion},
	number = {1},
	pages = {106--122},
	title = {{Robust time-domain full waveform inversion with normalized zero-lag cross-correlation objective function}},
	volume = {209},
	year = {2017}
}

@article{Metivier2018,
	abstract = {Optimal transport distance has been recently promoted as a tool to measure the discrepancy between observed and seismic data within the full-waveform-inversion strategy. This high-resolution seismic imaging method, based on a data-fitting procedure, suffers from the nonconvexity of the standard least-squares discrepancy measure, an issue commonly referred to as cycle skipping. The convexity of the optimal transport distance with respect to time shifts makes it a good candidate to provide a more convex misfit function. However, the optimal transport distance is defined only for the comparison of positive functions, while seismic data are oscillatory. A review of the different attempts proposed in the literature to overcome this difficulty is proposed. Their limitations are illustrated: Basically, the proposed strategies are either not applicable to real data, or they lose the convexity property of optimal transport. On this basis, we introduce a novel strategy based on the interpretation of the seismic data in the graph space. Each individual trace is considered, after discretization, as a set of Dirac points in a 2D space, where the amplitude becomes a geometric attribute of the data. This ensures the positivity of the data, while preserving the geometry of the signal. The differentiability of the misfit function is obtained by approximating the Dirac distributions through 2D Gaussian functions. The interest of this approach is illustrated numerically by computing misfit-function maps in schematic examples before moving to more realistic synthetic full-waveform exercises, including the Marmousi model. The better convexity of the graph-based optimal transport distance is shown. On the Marmousi model, starting from a 1D linearly increasing initial model, with data without low frequencies (no energy less than 3Hz), a meaningful estimation of the P-wave velocity model is recovered, outperforming previously proposed optimal-transport-based misfit functions.},
	author = {M{\'{e}}tivier, Ludovic and Allain, Aude and Brossier, Romain and M{\'{e}}rigot, Quentin and Oudet, Edouard and Virieux, Jean},
	doi = {10.1190/geo2017-0807.1},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\'{e}}tivier et al. - 2018 - Optimal transport for mitigating cycle skipping in full-waveform inversion A graph-space transform approach.pdf:pdf},
	issn = {19422156},
	journal = {Geophysics},
	keywords = {Full-waveform inversion,Imaging,Inversion,Signal processing,Wave propagation},
	mendeley-groups = {DAAD},
	number = {5},
	pages = {R515--R540},
	title = {{Optimal transport for mitigating cycle skipping in full-waveform inversion: A graph-space transform approach}},
	volume = {83},
	year = {2018}
}

@article{Gomez2017,
	author = {G{\'{o}}mez, Leonardo and Pestana*, Reynam C.},
	doi = {10.1190/sbgf2017-058},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}mez, Pestana - 2017 - Full-waveform inversion using alternative objective functions in the presence of noise and uncertainties of sou.pdf:pdf},
	number = {1},
	pages = {296--301},
	title = {{Full-waveform inversion using alternative objective functions in the presence of noise and uncertainties of source signature}},
	year = {2017}
}

@article{Pratt1999,
	author = {Pratt, R Gerhard and Shipp, Richard M},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratt, Shipp - 1999 - Seismic waveform inversion in the frequency domain , Part 2 Fault delineation in sediments using crosshole data.pdf:pdf},
	number = {3},
	pages = {902--914},
	title = {{Seismic waveform inversion in the frequency domain , Part 2 : Fault delineation in sediments using crosshole data}},
	volume = {64},
	year = {1999}
}


@article{Plessix2006,
	abstract = {Estimating the model parameters from measured data generally consists of minimizing an error functional. A classic technique to solve a minimization problem is to successively determine the minimum of a series of linearized problems. This formulation requires the Fr{\'{e}}chet derivatives (the Jacobian matrix), which can be expensive to compute. If the minimization is viewed as a non-linear optimization problem, only the gradient of the error functional is needed. This gradient can be computed without the Fr{\'{e}}chet derivatives. In the 1970s, the adjoint-state method was developed to efficiently compute the gradient. It is now a well-known method in the numerical community for computing the gradient of a functional with respect to the model parameters when this functional depends on those model parameters through state variables, which are solutions of the forward problem. However, this method is less well understood in the geophysical community. The goal of this paper is to review the adjoint-state method. The idea is to define some adjoint-state variables that are solutions of a linear system. The adjoint-state variables are independent of the model parameter perturbations and in a way gather the perturbations with respect to the state variables. The adjoint-state method is efficient because only one extra linear system needs to be solved. Several applications are presented. When applied to the computation of the derivatives of the ray trajectories, the link with the propagator of the perturbed ray equation is established. {\textcopyright} 2006 The Authors Journal compilation {\textcopyright} 2006 RAS.},
	author = {Plessix, Rene Edouard},
	doi = {10.1111/j.1365-246X.2006.02978.x},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Plessix - 2006 - A review of the adjoint-state method for computing the gradient of a functional with geophysical applications.pdf:pdf},
	issn = {0956540X},
	journal = {Geophysical Journal International},
	keywords = {Adjoint state,Gradient,Migration,Tomography},
	mendeley-groups = {FWI},
	number = {2},
	pages = {495--503},
	title = {{A review of the adjoint-state method for computing the gradient of a functional with geophysical applications}},
	volume = {167},
	year = {2006}
}

@article{Guo2021,
	abstract = {Seismic full waveform inversion (FWI) is a powerful method for estimating quantitative subsurface physical parameters from seismic data. As the FWI is a nonlinear problem, the linearized approach updates model iteratively from an initial model, which can get trapped in local minima. In the presence of a high-velocity contrast, such as at Moho, the reflection coefficient and recorded waveforms from wide-aperture seismic acquisition are extremely nonlinear around critical angles. The problem at the Moho is further complicated by the interference of lower crustal (Pg) and upper mantle (Pn) turning ray arrivals with the critically reflected Moho arrivals (PmP). In order to determine velocity structure near Moho, a nonlinear method should be used. We propose to solve this strong nonlinear FWI problem at Moho using a trans-dimensional Markov chain Monte Carlo (MCMC) method, where the earth model between lower crust and upper mantle is ideally parametrized with a 1-D assumption using a variable number of velocity interfaces. Different from common MCMC methods that require determining the number of unknown as a fixed prior before inversion, trans-dimensional MCMC allows the flexibility for an automatic estimation of both the model complexity (e.g. the number of velocity interfaces) and the velocity-depth structure from the data. We first test the algorithm on synthetic data using four representative Moho models and then apply to an ocean bottom seismometer (OBS) data from the Mid-Atlantic Ocean. A 2-D finite-difference solution of an acoustic wave equation is used for data simulation at each iteration of MCMC search, for taking into account the lateral heterogeneities in the upper crust, which is constrained from traveltime tomography and is kept unchanged during inversion; the 1-D model parametrization near Moho enables an efficient search of the trans-dimensional model space. Inversion results indicate that, with very little prior and the wide-aperture seismograms, the trans-dimensional FWI method is able to infer the posterior distribution of both the number of velocity interfaces and the velocity-depth model for a strong nonlinear problem, making the inversion a complete data-driven process. The distribution of interface matches the velocity discontinuities. We find that the Moho in the study area is a transition zone of.7 km, or a sharp boundary with velocities from around 7 km s-1 in the lower crust to 8 km s-1 of the upper mantle; both provide nearly identical waveform match for the field data. The ambiguity comes from the resolution limit of the band-limited seismic data and limited offset range for PmP arrivals.},
	author = {Guo, Peng and Singh, Satish C. and Vaddineni, Venkata A. and Visser, Gerhard and Grevemeyer, Ingo and Saygin, Erdinc},
	doi = {10.1093/gji/ggaa505},
	file = {:home/vikas/Desktop/papers/ggaa505.pdf:pdf},
	issn = {1365246X},
	journal = {Geophysical Journal International},
	keywords = {Body waves,Crustal imaging,Probability distributions,Waveform inversion},
	number = {2},
	pages = {1056--1078},
	publisher = {Oxford University Press},
	title = {{Nonlinear full waveform inversion of wide-aperture OBS data for Moho structure using a trans-dimensional Bayesian method}},
	volume = {224},
	year = {2021}
}

@article{Geng2018,
	abstract = {Full-waveform inversion (FWI) is a highly non-linear inverse problem, normally solved iteratively, with each iteration involving an update constructed through linear operations on the residuals. Incorporating a flexible degree of non-linearity within each update may have important consequences for convergence rates, determination of low model wavenumbers and discrimination of parameters. We examine one approach for doing so, wherein higher order scattering terms are included within the sensitivity kernel during the construction of the descent direction, adjusting it away from that of the standard Gauss-Newton approach. These scattering terms are naturally admitted when we construct the sensitivity kernel by varying not the current but the to-be-updated model at each iteration. Linear and/or non-linear inverse scattering methodologies allow these additional sensitivity contributions to be computed from the current data residuals within any given update.We show that in the presence of pre-critical reflection data, the error in a second-order non-linear update to a background of s0 is, in our scheme, proportional to at most ($\Delta$s/s0)3 in the actual parameter jump $\Delta$s causing the reflection. In contrast, the error in a standard Gauss-Newton FWI update is proportional to ($\Delta$s/s0)2. For numerical implementation of more complex cases, we introduce a non-linear frequency-domain scheme, with an inner and an outer loop. A perturbation is determined from the data residuals within the inner loop, and a descent direction based on the resulting non-linear sensitivity kernel is computed in the outer loop. We examine the response of this non-linear FWI using acoustic single-parameter synthetics derived from the Marmousi model. The inverted results vary depending on data frequency ranges and initial models, but we conclude that the non-linear FWI has the capability to generate high-resolution model estimates in both shallow and deep regions, and to converge rapidly, relative to a benchmark FWI approach involving the standard gradient.},
	author = {Geng, Yu and Pan, Wenyong and Innanen, Kristopher A.},
	doi = {10.1093/gji/ggy002},
	file = {:home/vikas/Desktop/papers/ggy002.pdf:pdf},
	issn = {1365246X},
	journal = {Geophysical Journal International},
	keywords = {Inverse theory,Theoretical seismology,Wave scattering and diffraction,Waveform inversion},
	number = {2},
	pages = {739--756},
	title = {{Frequency-domain full-waveform inversion with non-linear descent directions}},
	volume = {213},
	year = {2018}
}

@article{Crase1990,
	abstract = {Nonlinear elastic waveform inversion has advanced to the point where it is now possible to invert real multiple-shot seismic data. The iterative gradient algorithm that we employ can readily accommodate robust minimization criteria which tend to handle many types of seismic noise better than the commonly used least-squares minimization criteria. Although there are many robust criteria from which to choose, we have tested only a few. In particular, the Cauchy criterion and the hyperbolic secant criterion perform very well. Although the real data set, which we invert using the sech criterion, is marine (pressure sources and receivers) and is very much dominated by unconverted P waves, we can, for the most part, resolve the short wavelengths of both P impedance and S impedance. -from Authors},
	author = {Crase, E. and Pica, A. and Noble, M. and McDonald, J. and Tarantola, A.},
	doi = {10.1190/1.1442864},
	file = {:home/vikas/Downloads/1990-noble-geophysics-1.pdf:pdf},
	issn = {00168033},
	journal = {Geophysics},
	number = {5},
	pages = {527--538},
	title = {{Robust elastic nonlinear waveform inversion: application to real data}},
	volume = {55},
	year = {1990}
}

@book{FitchnerETH2015,
	abstract = {Inferring interior properties of the Sun from photospheric measurements of the seismic wavefield constitutes the helioseismic inverse problem. Deviations in seismic measurements (such as wave travel times) from their fiducial values estimated for a given model of the solar interior imply that the model is inaccurate. In this section, we implement iterative inversions to obtain the sub-surface structure of perturbations. The model can be successively improved using either steepest descent or Krylov-subspace techniques such as conjugate gradient, or limited-memory Broyden-Fletcher-Goldfarb-Shanno method.},
	author = {Fitchner(ETH)},
	booktitle = {SpringerBriefs in Mathematics},
	doi = {https://doi.org/10.1007/978-3-642-15807-0},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fitchner(ETH) - 2015 - Full waveform inversion.pdf:pdf},
	isbn = {9783642158063},
	issn = {21918201},
	keywords = {Adjoint Method,Meridional Circulation,Solar Interior,Sound Speed,Travel Time},
	pages = {75--103},
	title = {{Full waveform inversion}},
	year = {2015}
}

@article{Bunks1995a,
	abstract = {Iterative inversion methods have been unsuccessful at inverting seismic data obtained from complicated earth models, the primary difficulty being the presence of of numerous local minima in the objective function. The presence of local minima at all scales in the seismic inversion problem prevent iterative methods of inversion from attaining a reasonable degree of convergence to the neighborhood of the global minimum. The multigrid method is a technique that improves the performance of iterative inversion by decomposing the problem by scale. The multigrid method is applied to a subsampled, low-frequency version of the Marmousi data set. The results show that iterative inversion methods perform much better when employed with a decomposition by scale. Furthermore, the method greatly reduces the computational burden of the inversion that will be of importance for 3-D extensions to the method. -from Authors},
	author = {Bunks, C. and Saleck, F. M. and Zaleski, S. and Chavent, G.},
	doi = {10.1190/1.1443880},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bunks et al. - 1995 - Multiscale seismic waveform inversion.pdf:pdf},
	issn = {00168033},
	journal = {Geophysics},
	number = {5},
	pages = {1457--1473},
	title = {{Multiscale seismic waveform inversion}},
	volume = {60},
	year = {1995}
}

@article{Schafer2014,
	abstract = {},
	author = {Sch{\"{a}}fer, M. and Groos, L. and Forbriger, T. and Bohlen, T.},
	doi = {10.1093/gji/ggu171},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sch{\"{a}}fer et al. - 2014 - Line-source simulation for shallow-seismic data. Part 2 Full-waveform inversion-a synthetic 2-D case study.pdf:pdf},
	issn = {1365246X},
	journal = {Geophysical Journal International},
	keywords = {Seismic tomography,Surface waves and free oscillations,Wave propagation},
	number = {3},
	pages = {1405--1418},
	title = {{Line-source simulation for shallow-seismic data. Part 2: Full-waveform inversion-a synthetic 2-D case study}},
	volume = {198},
	year = {2014}
}

@article{Sirgue2004,
	abstract = {Prestack migration and/or inversion may be implemented in either the time or the frequency domain. In the frequency domain, it is possible to discretize the frequencies with a much larger sampling interval than that dictated by the sampling theorem and still obtain an imaging result that does not suffer from aliasing (wrap around) in the depth domain. The selection of input frequencies can be reduced when a range of offsets is available; this creates a redundancy of information in the wavenumber coverage of the target. In order to optimize the use of this information, we define a new discretization strategy that depends on the maximum effective offset present in the surface seismic survey: the larger the range of offsets, the fewer frequencies are required. The strategy, exact in a homogeneous 1D earth, selects frequencies by making use of the well-known effect of image stretch in normal-moveout (NMO) correction and in migration (usually considered detrimental for the imaging). The strategy is also useful in more general earth models: we apply it to the 2D Marmousi model and recover a continuous range of wavenumbers using only three input frequencies. The Marmousi inversion result accurately predicts all other data frequencies, demonstrating the redundancy of the data. {\textcopyright} 2004 Society of Exploration Geophysicists. All rights reserved.},
	author = {Sirgue, Laurent and Pratt, R. Gerhard},
	doi = {10.1190/1.1649391},
	file = {:home/vikas/Downloads/sirgue-pratt-2004-efficient-waveform-inversion-and-imaging-a-strategy-for-selecting-temporal-frequencies.pdf:pdf},
	issn = {00168033},
	journal = {Geophysics},
	number = {1},
	pages = {231--248},
	title = {{Efficient waveform inversion and imaging: A strategy for selecting temporal frequencies}},
	volume = {69},
	year = {2004}
}

@article{TenKroode2013,
	abstract = {We considered the importance of low frequencies in seismic reflection data for enhanced resolution, better penetration, and waveform and impedance inversion. We reviewed various theoretical arguments underlining why adding low frequencies may be beneficial and provided experimental evidence for the improvements by several case studies with recently acquired broadband data. We discussed where research and development efforts in the industry with respect to low frequencies should be focusing.},
	author = {ten Kroode, Fons and Bergler, Steffen and Corsten, Cees and de Maag, Jan Willem and Strijbos, Floris and Tijhof, Henk},
	doi = {10.1190/GEO2012-0294.1},
	file = {:home/vikas/Desktop/papers/ten-kroode-et-al-2013-broadband-seismic-data-the-importance-of-low-frequencies.pdf:pdf},
	issn = {19422156},
	journal = {Geophysics},
	number = {2},
	pages = {WA3--WA14},
	title = {{Broadband seismic data-The importance of low frequencies}},
	volume = {78},
	year = {2013}
}

@article{Ravaut2004,
	abstract = {An application of full-waveform tomography to dense onshore wide-aperture seismic data recorded in a complex geological setting (thrust belt) is presented. The waveform modelling and tomography are implemented in the frequency domain. The modelling part is solved with a finite-difference method applied to the visco-acoustic wave equation. The inversion is based on a local gradient method. Only the P-wave velocity is involved in the inversion. The inversion is applied iteratively to discrete frequency components by proceeding from low to high frequencies. This defines a multiscale imaging in the sense that high wavenumbers are progressively incorporated in images. The linearized waveform tomography requires an accurate starting velocity model that has been developed by first-arrival traveltime tomography. After specific pre-processing of the data, 16 frequency components ranging between 5.4 and 20 Hz were inverted. Ten iterations were computed per frequency component leading to 160 tomographic models. The waveform tomography has successfully imaged southwest-dipping structures previously identified from other geophysical data as being associated with high-resistivity bodies. The relevance of the tomographic images is locally demonstrated by comparison of a velocity-depth function extracted from the waveform tomography models with a coincident vertical seismic profiling (VSP) log available on the profile. Moreover, comparison between observed and synthetic seismograms computed in the (starting) traveltime and waveform tomography models demonstrates unambiguously that the waveform tomography successfully predicts for wide-angle reflections from southwest-dipping geological structures. This study demonstrates that the combination of first-arrival traveltime and frequency-domain fall-waveform tomographies applied to dense wide-aperture seismic data is a promising approach to quantitative imaging of complex geological structures. Indeed, wide-aperture acquisition geometries offer the opportunity to develop an accurate background velocity model for the subsequent waveform tomography. This is critical, because the building of the macromodel remains an open question when only near-vertical reflection data are considered. {\textcopyright} 2004 RAS.},
	author = {Ravaut, C. and Operto, S. and Improta, L. and Virieux, J. and Herrero, A. and Dell'Aversana, P.},
	doi = {10.1111/j.1365-246X.2004.02442.x},
	file = {:home/vikas/Desktop/papers/159-3-1032.pdf:pdf},
	issn = {0956540X},
	journal = {Geophysical Journal International},
	keywords = {Finite-difference methods,Thrust belt,Traveltime and full waveform inversions,Wide-aperture seismic data},
	number = {3},
	pages = {1032--1056},
	title = {{Multiscale imaging of complex structures from multifold wide-aperture seismic data by frequency-domain full-waveform tomography: Application to a thrust belt}},
	volume = {159},
	year = {2004}
}

@article{Liu2017,
	abstract = {In fullwaveforminversion (FWI) with the least-squares (L2) norm, the direct amplitude matching is never perfect and the accurate estimation of the seismic source strength is not always available. In contrast, the normalized zero-lag cross-correlation objective function relaxes on the amplitude constraints and emphasizes the phase information when measuring the closeness between the simulated and observed data. This FWI method becomes insensitive to differences in amplitude. Based on this property, we investigate the effectiveness and robustness of FWI with the normalized zero-lag cross-correlation function (CFWI) against the noise and unpredictable amplitude of the data that cannot be modelled by the wavefield extrapolation operator. The effectiveness is firstly tested by noise-free data and data contaminated by Gaussian white noise. In addition, CFWI can invert the data set with incorrect source strength when compared with the L2 norm. Moreover, the data set with incorrect source signature illustrates that CFWI is slightly more insensitive to the error in source signature than the L2 norm. However, a source inversion is still needed when the source signature is severely erroneous. With non-Gaussian noise data, such as contaminated by strong ground motion noise and even by spike-type noise, CFWI provides a comparable result with that of the robust Huber norm. Numerical experiments with non-Gaussian noise also indicate that CFWI can suppress noise in data to produce clearer images when compared with the Huber norm. Besides, CFWI is free of the threshold criterion that controls the transition between the L2 and L1 norms used with the Huber and Hybrid norms and therefore free from tedious trial-and-error tests. Several numerical examples support that CFWI is an alternative and reliable inversion method. However, a numerical test with a 1-D initial model confirms that CFWI is more sensitive to the cycle-skipping problem caused by less-accurate initial velocity model than the L2 norm, which is due to the wrong matched events contributing to spurious local minima of the objective function of CFWI, but to an increase in the objective function used with the L2 norm.},
	author = {Liu, Youshan and Teng, Jiwen and Xu, Tao and Wang, Yanghua and Liu, Qinya and Badal, Jos{\'{e}}},
	doi = {10.1093/gji/ggw485},
	file = {:home/vikas/Desktop/papers/ggw485.pdf:pdf},
	issn = {1365246X},
	journal = {Geophysical Journal International},
	keywords = {Inverse theory,Seismology,Waveform inversion},
	number = {1},
	pages = {106--122},
	title = {{Robust time-domain full waveform inversion with normalized zero-lag cross-correlation objective function}},
	volume = {209},
	year = {2017}
}

@article{Chi2015,
	abstract = {Because modeling for full-waveform inversion (FWI) cannot produce reflections unless the velocity model has the scattering potential (high wavenumbers), using a migration/demigration process to generate modeling data, which is a key step in what is now known as reflection FWI (RFWI), is a credible alternative to tackle the reflection nonlinearity associated with FWI. However, because RFWI depends on a conventional data residual or zero-lag correlation objective function, high nonlinearity can still exist when the true amplitude migration is not used, as well as at far offsets due to cycle skipping. To avoid the cycle skipping and the need for a true amplitude migration, we have developed a correlation-based reflection full-waveform inversion method to update the low-wavenumber components of the velocity model. The success of this method relies on a sensitivity kernel decomposition and a correlation-based objective function. The sensitivity kernel decomposition makes it possible to separate out the contributions of different subkernels and to smear the reflected wave residuals along the "rabbit-ear" wavepath to obtain middle and deep background model estimates. The correlation-based objective function measures differences in kinematic information and behaves in a more linear way than the traditional waveform residual misfit. Moreover, our approach is less sensitive to the frequency content and amplitude information of the seismic data, enabling reliable background velocity estimates to be obtained without the need for low frequencies and full-physics modeling. Because the kinematic features of reflected waves are described correctly, the inversion result of the proposed method can be used as a migration model or an initial model for conventional FWI to achieve a correct high-wavenumber model update.},
	author = {Chi, Benxin and Dong, Liangguo and Liu, Yuzhu},
	doi = {10.1190/GEO2014-0345.1},
	file = {:home/vikas/Desktop/papers/chi-et-al-2015-correlation-based-reflection-full-waveform-inversion.pdf:pdf},
	issn = {19422156},
	journal = {Geophysics},
	number = {4},
	pages = {R189--R202},
	title = {{Correlation-based reflection full-waveform inversion}},
	volume = {80},
	year = {2015}
}

@article{Metivier2018,
	abstract = {Optimal transport distance has been recently promoted as a tool to measure the discrepancy between observed and seismic data within the full-waveform-inversion strategy. This high-resolution seismic imaging method, based on a data-fitting procedure, suffers from the nonconvexity of the standard least-squares discrepancy measure, an issue commonly referred to as cycle skipping. The convexity of the optimal transport distance with respect to time shifts makes it a good candidate to provide a more convex misfit function. However, the optimal transport distance is defined only for the comparison of positive functions, while seismic data are oscillatory. A review of the different attempts proposed in the literature to overcome this difficulty is proposed. Their limitations are illustrated: Basically, the proposed strategies are either not applicable to real data, or they lose the convexity property of optimal transport. On this basis, we introduce a novel strategy based on the interpretation of the seismic data in the graph space. Each individual trace is considered, after discretization, as a set of Dirac points in a 2D space, where the amplitude becomes a geometric attribute of the data. This ensures the positivity of the data, while preserving the geometry of the signal. The differentiability of the misfit function is obtained by approximating the Dirac distributions through 2D Gaussian functions. The interest of this approach is illustrated numerically by computing misfit-function maps in schematic examples before moving to more realistic synthetic full-waveform exercises, including the Marmousi model. The better convexity of the graph-based optimal transport distance is shown. On the Marmousi model, starting from a 1D linearly increasing initial model, with data without low frequencies (no energy less than 3Hz), a meaningful estimation of the P-wave velocity model is recovered, outperforming previously proposed optimal-transport-based misfit functions.},
	author = {M{\'{e}}tivier, Ludovic and Allain, Aude and Brossier, Romain and M{\'{e}}rigot, Quentin and Oudet, Edouard and Virieux, Jean},
	doi = {10.1190/geo2017-0807.1},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\'{e}}tivier et al. - 2018 - Optimal transport for mitigating cycle skipping in full-waveform inversion A graph-space transform approach.pdf:pdf},
	issn = {19422156},
	journal = {Geophysics},
	keywords = {Full-waveform inversion,Imaging,Inversion,Signal processing,Wave propagation},
	mendeley-groups = {DAAD},
	number = {5},
	pages = {R515--R540},
	title = {{Optimal transport for mitigating cycle skipping in full-waveform inversion: A graph-space transform approach}},
	volume = {83},
	year = {2018}
}

@article{Brossier2016,
	author = {Brossier, R and Oudet, E and Virieux, J},
	doi = {10.1093/gji/ggw014},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brossier, Oudet, Virieux - 2016 - Measuring the misfit between seismograms using an optimal transport distance application to full wave.pdf:pdf},
	keywords = {1 i n t,computational seismology,controlled source seis-,full waveform inversion,fwi,inverse theory,is a data fitting,mology,numerical approximation and analysis,procedure aiming,ro d u c,t i o n,wave propagation},
	mendeley-groups = {DAAD},
	pages = {345--377},
	title = {{Measuring the misfit between seismograms using an optimal transport distance : application to full waveform inversion}},
	year = {2016}
}

@article{Metivier2016,
	abstract = {The use of optimal transport distance has recently yielded significant progress in image processing for pattern recognition, shape identification, and histograms matching. In this study, the use of this distance is investigated for a seismic tomography problem exploiting the complete waveform; the full waveform inversion. In its conventional formulation, this high resolution seismic imaging method is based on the minimization of the L 2 distance between predicted and observed data. Application of this method is generally hampered by the local minima of the associated L 2 misfit function, which correspond to velocity models matching the data up to one or several phase shifts. Conversely, the optimal transport distance appears as a more suitable tool to compare the misfit between oscillatory signals, for its ability to detect shifted patterns. However, its application to the full waveform inversion is not straightforward, as the mass conservation between the compared data cannot be guaranteed, a crucial assumption for optimal transport. In this study, the use of a distance based on the Kantorovich-Rubinstein norm is introduced to overcome this difficulty. Its mathematical link with the optimal transport distance is made clear. An efficient numerical strategy for its computation, based on a proximal splitting technique, is introduced. We demonstrate that each iteration of the corresponding algorithm requires solving the Poisson equation, for which fast solvers can be used, relying either on the fast Fourier transform or on multigrid techniques. The development of this numerical method make possible applications to industrial scale data, involving tenths of millions of discrete unknowns. The results we obtain on such large scale synthetic data illustrate the potentialities of the optimal transport for seismic imaging. Starting from crude initial velocity models, optimal transport based inversion yields significantly better velocity reconstructions than those based on the L 2 distance, in 2D and 3D contexts.},
	author = {M{\'{e}}tivier, L. and Brossier, R. and M{\'{e}}rigot, Q. and Oudet, E. and Virieux, J.},
	doi = {10.1088/0266-5611/32/11/115008},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\'{e}}tivier et al. - 2016 - An optimal transport approach for seismic tomography Application to 3D full waveform inversion.pdf:pdf},
	issn = {13616420},
	journal = {Inverse Problems},
	keywords = {full waveform inversion,non-smooth convex optimization,optimal transport,seismic imaging,tomography, proximal splitting},
	mendeley-groups = {DAAD},
	number = {11},
	publisher = {IOP Publishing},
	title = {{An optimal transport approach for seismic tomography: Application to 3D full waveform inversion}},
	volume = {32},
	year = {2016}
}

@article{Chi2014,
	abstract = {Full waveform inversion (FWI) has been a successful tool to build high resolution velocity models, but it is affected by a local minima problem. The conventional multi-scale strategy to tackle this severe problem may not work for real seismic data without long offsets and low frequency data. We use an envelope-based objective function FWI method to provide the long wavelength components of the velocity model for the traditional FWI. The gradient can be computed efficiently with the adjoint state method without any additional computational cost. Simple models are used to prove that the envelope-based objective function is more convex than the traditional misfit function, thus the cycle-skipping problem can be mitigated. Due to the envelope demodulation effect, the adjoint source of the envelope-based FWI contains abundant low frequency information, therefore the gradient tends to sense the low wavenumber model update. A Marmousi synthetic data example illustrates that the envelope-based FWI method can provide an adequately accurate initial model for the traditional FWI approach even when the initial model is far from the true model and low-frequency data are missing. {\textcopyright} 2014 Elsevier B.V.},
	author = {Chi, Benxin and Dong, Liangguo and Liu, Yuzhu},
	doi = {10.1016/j.jappgeo.2014.07.010},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chi, Dong, Liu - 2014 - Full waveform inversion method using envelope objective function without low frequency data.pdf:pdf},
	issn = {09269851},
	journal = {Journal of Applied Geophysics},
	keywords = {Adjoint-state method,Envelope,Full waveform inversion,Nonlinearity,Objective function},
	mendeley-groups = {FWI},
	pages = {36--46},
	publisher = {Elsevier B.V.},
	title = {{Full waveform inversion method using envelope objective function without low frequency data}},
	url = {http://dx.doi.org/10.1016/j.jappgeo.2014.07.010},
	volume = {109},
	year = {2014}
}

@article{Borisov2018,
	abstract = {Full-waveform inversion (FWI) is a powerful method for estimating the earth's material properties. We demonstrate that surface-wave-driven FWI is well-suited to recovering near-surface structures and effective at providing S-wave speed starting models for use in conventional body-wave FWI. Using a synthetic example based on the SEG Advanced Modeling phase II foothills model, we started with an envelope-based objective function to invert for shallow largescale heterogeneities. Then we used a waveform-difference objective function to obtain a higher-resolution model. To accurately model surface waves in the presence of complex tomography, we used a spectral-element wave-propagation solver. Envelope misfit functions are found to be effective at minimizing cycle-skipping issues in surface-wave inversions, and surface waves themselves are found to be useful for constraining complex near-surface features.},
	author = {Borisov, Dmitry and Modrak, Ryan and Gao, Fuchun and Tromp, Jeroen},
	doi = {10.1190/GEO2017-0081.1},
	file = {:home/vikas/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borisov et al. - 2018 - 3D elastic full-waveform inversion of surface waves in the presence of irregular topography using an envelope-ba.pdf:pdf},
	issn = {19422156},
	journal = {Geophysics},
	mendeley-groups = {DAAD},
	number = {1},
	pages = {R1--R11},
	title = {{3D elastic full-waveform inversion of surface waves in the presence of irregular topography using an envelope-based misfit function}},
	volume = {83},
	year = {2018}
}

@article{Arora1995,
	abstract = {A review of the methods for global optimization re- veals that most methods have been developed for unconstrained problems. They need to be extended to general constrained problems because most of the engineering applications have con- straints. Some of the methods can be easily extended while others need further work. It is also possible to transform a constrained problem to an unconstrained one by using penalty or augmented Lagrangian methods and solve the problem that way. Some of the global optimization methods find all the local minimum points while others find only a few of them. In any case, all the meth- ods require a very large number of calculations. Therefore, the computational effort to obtain a global solution is generally sub- stantial. The methods for global optimization can be divided into two broad categories: deterministic and stochastic. Some deter- ministic methods are based on certain assumptions on the cost function that are not easy to check. These methods are not very useful since they are not applicable to general problems. Other deterministic methods are based on certain heuristics which may not lead to the true global solution. Several stochastic methods have been developed as some variation of the pure random search. Some methods are useful for only discrete optimization problems while others can be used for both discrete and continuous prob- lems. Main characteristics of each method are identified and dis- cussed. The selection of a method for a particular application depends on several attributes, such as types of design variables, whether or not all local minima are desired, and availability of gradients of all the functions,},
	author = {Arora, J S and Elwakeil, O.A. and Chahande, A.I. and Hsieh, C.C.},
	file = {:home/vikas/Desktop/papers/BF01743964.pdf:pdf},
	journal = {Structural Optimization 9,},
	mendeley-groups = {global{\_}optimization},
	pages = {137--159},
	title = {{Review Paper Global optimization m e t h o d s for engineering applications : a review}},
	volume = {9},
	year = {1995}
}

@book{Torn1989,
	author = {T{\"{o}}rn, Aimo and {\v{Z}}ilinskas, Antanas},
	booktitle = {Lecture Notes in Computer Science},
	file = {:home/vikas/Desktop/papers/3-540-50871-6-3.pdf:pdf},
	isbn = {3540508716},
	pages = {1--24},
	title = {{Lecture Notes in Computer Science: Global Optimization}},
	url = {https://link.springer.com/10.1007/3-540-50871-6{\_}1},
	volume = {245},
	year = {1989}
}

@article{Locatelli2021,
	abstract = {Recent developments in (Global) Optimization are surveyed in this paper. We collected and commented quite a large number of recent references which, in our opinion, well represent the vivacity, deepness, and width of scope of current computational approaches and theoretical results about nonconvex optimization problems. Before the presentation of the recent developments, which are subdivided into two parts related to heuristic and exact approaches, respectively, we briefly sketch the origin of the discipline and observe what, from the initial attempts, survived, what was not considered at all as well as a few approaches which have been recently rediscovered, mostly in connection with machine learning.},
	author = {Locatelli, Marco and Schoen, Fabio},
	doi = {10.1016/j.ejco.2021.100012},
	file = {:home/vikas/Desktop/papers/1-s2.0-S2192440621001398-main.pdf:pdf},
	issn = {21924414},
	journal = {EURO Journal on Computational Optimization},
	keywords = {Exact methods,Global optimization,Heuristics},
	mendeley-groups = {global{\_}optimization},
	number = {October 2020},
	pages = {100012},
	publisher = {Elsevier Ltd},
	title = {{(Global) Optimization: Historical notes and recent developments}},
	url = {https://doi.org/10.1016/j.ejco.2021.100012},
	volume = {9},
	year = {2021}
}

@article{Ingber1989,
	abstract = {An algorithm is developed to statistically find the best global fit of a nonlinear nonconvex cost-function over a D-dimensional space. It is argued that this algorithm permits an annealing schedule for "temperature" T decreasing exponentially in annealing-time k, T = T0 exp(-ck1/D). The introduction of re-annealing also permits adaptation to changing insensitivities in the multi-dimensional parameter-space. This annealing schedule is faster than fast Cauchy annealing, where T = T0/k, and much faster than Boltzmann annealing, where T = T0/1n k. Applications are being made to fit empirical data to Lagrangians representing nonlinear Gaussian-Markovian systems. {\textcopyright} 1989.},
	author = {Ingber, L.},
	doi = {10.1016/0895-7177(89)90202-1},
	file = {:home/vikas/Desktop/papers/1-s2.0-0895717789902021-main.pdf:pdf},
	issn = {08957177},
	journal = {Mathematical and Computer Modelling},
	mendeley-groups = {global{\_}optimization},
	number = {8},
	pages = {967--973},
	title = {{Very fast simulated re-annealing}},
	volume = {12},
	year = {1989}
}

@article{Kirkpatrick1983,
	abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
	author = {Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P.},
	doi = {10.1126/science.220.4598.671},
	file = {:home/vikas/Desktop/papers/kirkpatrick (1983) optimization by simulated annealing.pdf:pdf},
	issn = {00368075},
	journal = {Science},
	mendeley-groups = {global{\_}optimization},
	number = {4598},
	pages = {671--680},
	pmid = {17813860},
	title = {{Optimization by simulated annealing}},
	volume = {220},
	year = {1983}
}

@article{Sacks1989,
	abstract = {The history, empirical evidence and classical explanations of the significant-digit (or Benford's) law are reviewed, followed by a summary of recent invariant-measure characterizations. Then a new statistical derivation of the law in the form of a CLT-like theorem for significant digits is presented. If distributions are selected at random (in any "unbiased" way) and random samples are then taken from each of these distributions, the significant digits of the combined sample will converge to the logarithmic (Benford) distribution. This helps explain and predict the appearance of the significant-digit phenomenon in many different emprical contexts and helps justify its recent application to computer design, mathematical modelling and detection of fraud in accounting data.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Sacks, Jerome and Welch, William J and Mitchell, Toby J and Wynn, Henry P},
	doi = {10.2307/2246134},
	eprint = {arXiv:1011.1669v3},
	file = {:home/vikas/Desktop/papers/1177011077.pdf:pdf},
	isbn = {0883-4237},
	issn = {2168-8745},
	journal = {Statistical Science},
	number = {4},
	pages = {409--435},
	pmid = {20948974},
	title = {{Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve, and extend access to Statistical Science. {\textregistered} www.jstor.org}},
	volume = {4},
	year = {1989}
}

@book{Katoch2021,
	abstract = {In this paper, the analysis of recent advances in genetic algorithms is discussed. The genetic algorithms ofgreat interest in research community are selected for analysis. This review will help the new and demanding researchers to provide thewider vision ofgenetic algorithms. The well-known algorithms and their implementation are presented with their pros and cons. The genetic operators and their usages are discussed with the aim of facilitating new researchers. The different research domains involved in genetic algorithms are covered. The future research directions in the area ofgenetic operators, fitness function and hybrid algorithms are discussed. This structured review will be helpful for research and graduate teaching.},
	author = {Katoch, Sourabh and Chauhan, Sumit Singh and Kumar, Vijay},
	booktitle = {Multimedia Tools and Applications},
	file = {:home/vikas/Desktop/papers/s11042-020-10139-6.pdf:pdf},
	isbn = {1104202010139},
	keywords = {Cross,Genetic algorithm,Metaheuristic,Optimization,crossover,genetic algorithm,metaheuristic,mutation,optimization,selection},
	mendeley-groups = {global{\_}optimization},
	pages = {8091--8126},
	publisher = {Multimedia Tools and Applications},
	title = {{Katoch2021{\_}Article{\_}AReviewOnGeneticAlgorithmPastP.pdf}},
	volume = {80},
	year = {2021}
}

@misc{Michalewicz1996,
	author = {Michalewicz, Zbigniew},
	booktitle = {Genetic Algorithms + Data Structures = Evolution Programs},
	file = {:home/vikas/Desktop/papers/Evolution Programs (3ed).PDF:PDF},
	mendeley-groups = {global{\_}optimization},
	pages = {388},
	title = {{Evolution Programs (3ed).PDF}},
	year = {1996}
}

@INPROCEEDINGS{kennedy,
	author={Kennedy, J. and Eberhart, R.},
	booktitle={Proceedings of ICNN'95 - International Conference on Neural Networks}, 
	title={Particle swarm optimization}, 
	year={1995},
	volume={4},
	number={},
	pages={1942-1948 vol.4},
	keywords={Particle swarm optimization;Birds;Educational institutions;Marine animals;Testing;Humans;Genetic algorithms;Optimization methods;Artificial neural networks;Performance evaluation},
	doi={10.1109/ICNN.1995.488968}
}

@article{Wang2018,
	abstract = {Particle swarm optimization (PSO) is a population-based stochastic optimization algorithm motivated by intelligent collective behavior of some animals such as flocks of birds or schools of fish. Since presented in 1995, it has experienced a multitude of enhancements. As researchers have learned about the technique, they derived new versions aiming to different demands, developed new applications in a host of areas, published theoretical studies of the effects of the various parameters and proposed many variants of the algorithm. This paper introduces its origin and background and carries out the theory analysis of the PSO. Then, we analyze its present situation of research and application in algorithm structure, parameter selection, topology structure, discrete PSO algorithm and parallel PSO algorithm, multi-objective optimization PSO and its engineering applications. Finally, the existing problems are analyzed and future research directions are presented.},
	author = {Wang, Dongshu and Tan, Dapei and Liu, Lei},
	doi = {10.1007/s00500-016-2474-6},
	file = {:home/vikas/Desktop/papers/s00500-016-2474-6.pdf:pdf},
	issn = {14337479},
	journal = {Soft Computing},
	keywords = {Discrete PSO,Multi-objective optimization PSO,Parallel PSO,Particle swarm optimization,Topology structure},
	mendeley-groups = {global{\_}optimization},
	number = {2},
	pages = {387--408},
	publisher = {Springer Berlin Heidelberg},
	title = {{Particle swarm optimization algorithm: an overview}},
	volume = {22},
	year = {2018}
}

@article{Shi1999,
	abstract = {We empirically study the performance of the particle swarm optimizer (PSO). Four different benchmark functions with asymmetric initial range settings are selected as testing functions. The experimental results illustrate the advantages and disadvantages of the PSO. Under all the testing cases, the PSO always converges very quickly towards the optimal positions but may slow its convergence speed when it is near a minimum. Nevertheless, the experimental results show that the PSO is a promising optimization method and a new approach is suggested to improve PSO's performance near the optima, such as using an adaptive inertia weight. {\textcopyright} 1999 IEEE.},
	author = {Shi, Yuhui and Eberhart, Russell C.},
	doi = {10.1109/CEC.1999.785511},
	file = {:home/vikas/Desktop/papers/Empirical{\_}study{\_}of{\_}particle{\_}swarm{\_}optimization.pdf:pdf},
	isbn = {0780355369},
	journal = {Proceedings of the 1999 Congress on Evolutionary Computation, CEC 1999},
	mendeley-groups = {global{\_}optimization},
	pages = {1945--1950},
	title = {{Empirical study of particle swarm optimization}},
	volume = {3},
	year = {1999}
}

@Inbook{Couceiro2016,
	author="Couceiro, Micael
	and Ghamisi, Pedram",
	title="Particle Swarm Optimization",
	bookTitle="Fractional Order Darwinian Particle Swarm Optimization: Applications and Evaluation of an Evolutionary Algorithm",
	year="2016",
	publisher="Springer International Publishing",
	address="Cham",
	pages="1--10",
	abstract="Bioinspired algorithms have been employed in situations where conventional optimization techniques cannot find a satisfactory solution, for example, when the function to be optimized is discontinuous, nondifferentiable, and/or presents too many nonlinearly related parameters (Floreano and Mattiussi, Bio-inspired artificial intelligence: Theories, methods, and technologies, 2008). One of the most well-known bioinspired algorithms used in optimization problems is particle swarm optimization (PSO), which basically consists of a machine-learning technique loosely inspired by birds flocking in search of food. More specifically, it consists of a number of particles that collectively move on the search space in search of the global optimum. This beginning chapter aims to introduce the main mechanics behind the traditional PSO, outlining its advantages and disadvantages, as well as summarizing the several extensions proposed in the literature over the past almost 20 years.",
	isbn="978-3-319-19635-0",
	doi="",
	url=""
}

@article{Ye2024,
	abstract = {An adaptive ensemble of surrogates assisted optimization algorithm combining local exploitation and global exploration (CLEGE) for computationally expensive problems is presented in this work. At the first level, two subspaces are created to accelerate the local search. Subspace1 is a promising region determined by fuzzy c-means clustering method, and Subspace2 is a promising region around the current best solution. Subsequently, the presented local exploitation using multi-spaces reduction is carried out to alternately achieve more promising points in the original global space, Subspace1 and Subspace2. Furthermore, the estimated mean square error of Kriging will be maximized for exploring the sparsely sampled regions, once CLEGE algorithm falls into the local optimum. Tested using twenty mathematical problems and one airfoil design optimization example, CLEGE shows superior sampling capability, better search efficiency and strong stability in solving the computationally expensive optimization problems.},
	author = {Ye, Pengcheng and Pan, Guang},
	doi = {10.1007/s00500-024-09688-x},
	file = {:home/vikas/Desktop/papers/s00500-024-09688-x-1.pdf:pdf},
	isbn = {0123456789},
	issn = {14337479},
	journal = {Soft Computing},
	keywords = {Global exploration,Global optimization,Local exploitation,Multi-spaces reduction,Surrogate models},
	mendeley-groups = {global{\_}optimization},
	number = {2017},
	publisher = {Springer Berlin Heidelberg},
	title = {{An optimization algorithm combining local exploitation and global exploration for computationally expensive problems}},
	url = {https://doi.org/10.1007/s00500-024-09688-x},
	volume = {0123456789},
	year = {2024}
}

@article{Dong2015,
	abstract = {In this paper, a novel kriging-based algorithm for global optimization of computationally expensive black-box functions is presented. This algorithm utilizes a multi-start approach to find all of the local optimal values of the surrogate model and performs searches within the neighboring area around these local optimal positions. Compared with traditional surrogate-based global optimization method, this algorithm provides another kind of balance between exploitation and exploration on kriging-based model. In addition, a new search strategy is proposed and coupled into this optimization process. The local search strategy employs a kind of improved “Minimizing the predictor” method, which dynamically adjusts search direction and radius until finds the optimal value. Furthermore, the global search strategy utilizes the advantage of kriging-based model in predicting unexplored regions to guarantee the reliability of the algorithm. Finally, experiments on 13 test functions with six algorithms are set up and the results show that the proposed algorithm is very promising.},
	author = {Dong, Huachao and Song, Baowei and Wang, Peng and Huang, Shuai},
	doi = {10.1007/s12206-015-0434-1},
	file = {:home/vikas/Desktop/papers/s12206-015-0434-1.pdf:pdf},
	issn = {1738494X},
	journal = {Journal of Mechanical Science and Technology},
	keywords = {Expensive black-box functions,Global optimization,Kriging-based algorithm,Local search strategy},
	mendeley-groups = {global{\_}optimization},
	number = {5},
	pages = {2121--2133},
	title = {{A kind of balance between exploitation and exploration on kriging for global optimization of expensive functions}},
	volume = {29},
	year = {2015}
}

@article{nirmit2024,
	author = {Dhabaria, Nirmit and Singh, Satish C},
	title = "{Hamiltonian Monte Carlo based elastic full-waveform inversion of wide-angle seismic data}",
	journal = {Geophysical Journal International},
	volume = {237},
	number = {3},
	pages = {1384-1399},
	year = {2024},
	month = {03},
	abstract = "{Full-waveform inversion (FWI) of seismic data provides quantitative constraints on subsurface structures. Despite its widespread success, FWI of data around the critical angle is challenging because of the abrupt change in amplitude and phase at the critical angle and the complex waveforms, especially in the presence of a sharp velocity contrast, such as at the Moho transition zone (MTZ). Furthermore, the interference of refracted lower crustal (Pg) and upper mantle (Pn) arrivals with the critically reflected Moho (PmP) arrivals in crustal and mantle studies makes the application of conventional FWI based on linearized model updates difficult. To address such a complex relationship between the model and data, one should use an inversion method based on a Bayesian formulation. Here, we propose to use a Hamiltonian Monte Carlo (HMC) method for FWI of wide-angle seismic data. HMC is a non-linear inversion technique where model updates follow the Hamiltonian mechanics while using the gradient information present in the probability distribution, making it similar to iterative gradient techniques like FWI. It also involves procedures for generating distant models for sampling the posterior distribution, making it a Bayesian method. We test the performance and applicability of HMC based elastic FWI by inverting the non-linear part of the synthetic seismic data from a three-layer and a complex velocity model, followed by the inversion of wide-angle seismic data recorded by two ocean bottom seismometers over a 70 Ma old oceanic crustal segment in the equatorial Atlantic Ocean. The inversion results from both synthetic and real data suggest that HMC based FWI is an appropriate method for inverting the non-linear part of seismic data for crustal studies.}",
	issn = {1365-246X},
	doi = {10.1093/gji/ggae112},
	url = {https://doi.org/10.1093/gji/ggae112},
	eprint = {https://academic.oup.com/gji/article-pdf/237/3/1384/57210592/ggae112.pdf},
}



